{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd0f232f7a67bcdde8954a49ae92fdbc95efe78334df4c989c783282833f84f4c73",
   "display_name": "Python 3.7.9 64-bit ('PythonData': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EIN</th>\n      <th>NAME</th>\n      <th>APPLICATION_TYPE</th>\n      <th>AFFILIATION</th>\n      <th>CLASSIFICATION</th>\n      <th>USE_CASE</th>\n      <th>ORGANIZATION</th>\n      <th>STATUS</th>\n      <th>INCOME_AMT</th>\n      <th>SPECIAL_CONSIDERATIONS</th>\n      <th>ASK_AMT</th>\n      <th>IS_SUCCESSFUL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10520599</td>\n      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n      <td>T10</td>\n      <td>Independent</td>\n      <td>C1000</td>\n      <td>ProductDev</td>\n      <td>Association</td>\n      <td>1</td>\n      <td>0</td>\n      <td>N</td>\n      <td>5000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10531628</td>\n      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n      <td>T3</td>\n      <td>Independent</td>\n      <td>C2000</td>\n      <td>Preservation</td>\n      <td>Co-operative</td>\n      <td>1</td>\n      <td>1-9999</td>\n      <td>N</td>\n      <td>108590</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10547893</td>\n      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n      <td>T5</td>\n      <td>CompanySponsored</td>\n      <td>C3000</td>\n      <td>ProductDev</td>\n      <td>Association</td>\n      <td>1</td>\n      <td>0</td>\n      <td>N</td>\n      <td>5000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10553066</td>\n      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n      <td>T3</td>\n      <td>CompanySponsored</td>\n      <td>C2000</td>\n      <td>Preservation</td>\n      <td>Trust</td>\n      <td>1</td>\n      <td>10000-24999</td>\n      <td>N</td>\n      <td>6692</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10556103</td>\n      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n      <td>T3</td>\n      <td>Independent</td>\n      <td>C1000</td>\n      <td>Heathcare</td>\n      <td>Trust</td>\n      <td>1</td>\n      <td>100000-499999</td>\n      <td>N</td>\n      <td>142590</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df = application_df.drop(labels=[\"EIN\", \"NAME\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_counts = application_df[\"APPLICATION_TYPE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which values to replace if counts are less than ...?\n",
    "replace_application = list(application_counts[application_counts<500].index)\n",
    "replace_application\n",
    "# Replace in dataframe\n",
    "for app in replace_application:\n",
    "    application_df[\"APPLICATION_TYPE\"] =application_df[\"APPLICATION_TYPE\"].replace(app,\"Other\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_counts = application_df[\"CLASSIFICATION\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_class = list(classification_counts[classification_counts<2000].index)\n",
    "# Replace in dataframe\n",
    "for cls in replace_class:\n",
    "    application_df.CLASSIFICATION = application_df.CLASSIFICATION.replace(cls,\"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps = list(application_df.dtypes[application_df.dtypes ==\"object\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(application_df[apps]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(apps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "application_df = application_df.merge(encode_df, left_index =True, right_index=True)\n",
    "application_df = application_df.drop(labels=apps, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split or preprocessed data inot our features and tarte arrays\n",
    "y = application_df[\"IS_SUCCESSFUL\"].values.reshape(-1,1)\n",
    "X = application_df.drop(\"IS_SUCCESSFUL\", axis=1).values\n",
    "\n",
    "#Split the preprocessed data into a traiing and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_3 (Dense)              (None, 80)                3360      \n_________________________________________________________________\ndense_4 (Dense)              (None, 30)                2430      \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 31        \n=================================================================\nTotal params: 5,821\nTrainable params: 5,821\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "num_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1= 80\n",
    "nn = tf.keras.models.Sequential()\n",
    "hidden_nodes_layer2 = 30\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=num_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "- 0s 401us/step - loss: 0.5374 - accuracy: 0.7376\n",
      "Epoch 111/300\n",
      "804/804 [==============================] - 0s 412us/step - loss: 0.5407 - accuracy: 0.7366\n",
      "Epoch 112/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5419 - accuracy: 0.7347\n",
      "Epoch 113/300\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5476 - accuracy: 0.7298\n",
      "Epoch 114/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5401 - accuracy: 0.7379\n",
      "Epoch 115/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5395 - accuracy: 0.7358\n",
      "Epoch 116/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5444 - accuracy: 0.7315\n",
      "Epoch 117/300\n",
      "804/804 [==============================] - 0s 404us/step - loss: 0.5473 - accuracy: 0.7326\n",
      "Epoch 118/300\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5397 - accuracy: 0.7364\n",
      "Epoch 119/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5372 - accuracy: 0.7375\n",
      "Epoch 120/300\n",
      "804/804 [==============================] - 0s 403us/step - loss: 0.5399 - accuracy: 0.7372\n",
      "Epoch 121/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5392 - accuracy: 0.7362\n",
      "Epoch 122/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5409 - accuracy: 0.7355\n",
      "Epoch 123/300\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5420 - accuracy: 0.7346\n",
      "Epoch 124/300\n",
      "804/804 [==============================] - 0s 459us/step - loss: 0.5414 - accuracy: 0.7358\n",
      "Epoch 125/300\n",
      "804/804 [==============================] - 0s 422us/step - loss: 0.5410 - accuracy: 0.7376\n",
      "Epoch 126/300\n",
      "804/804 [==============================] - 0s 415us/step - loss: 0.5409 - accuracy: 0.7371\n",
      "Epoch 127/300\n",
      "804/804 [==============================] - 0s 429us/step - loss: 0.5347 - accuracy: 0.7395\n",
      "Epoch 128/300\n",
      "804/804 [==============================] - 0s 449us/step - loss: 0.5448 - accuracy: 0.7307\n",
      "Epoch 129/300\n",
      "804/804 [==============================] - 0s 429us/step - loss: 0.5385 - accuracy: 0.7371\n",
      "Epoch 130/300\n",
      "804/804 [==============================] - 0s 420us/step - loss: 0.5368 - accuracy: 0.7388\n",
      "Epoch 131/300\n",
      "804/804 [==============================] - 0s 420us/step - loss: 0.5388 - accuracy: 0.7399\n",
      "Epoch 132/300\n",
      "804/804 [==============================] - 0s 407us/step - loss: 0.5404 - accuracy: 0.7334\n",
      "Epoch 133/300\n",
      "804/804 [==============================] - 0s 425us/step - loss: 0.5336 - accuracy: 0.7398\n",
      "Epoch 134/300\n",
      "804/804 [==============================] - 0s 445us/step - loss: 0.5387 - accuracy: 0.7389\n",
      "Epoch 135/300\n",
      "804/804 [==============================] - 0s 428us/step - loss: 0.5365 - accuracy: 0.7392\n",
      "Epoch 136/300\n",
      "804/804 [==============================] - 0s 446us/step - loss: 0.5389 - accuracy: 0.7381\n",
      "Epoch 137/300\n",
      "804/804 [==============================] - 0s 439us/step - loss: 0.5389 - accuracy: 0.7365\n",
      "Epoch 138/300\n",
      "804/804 [==============================] - 0s 419us/step - loss: 0.5413 - accuracy: 0.7350\n",
      "Epoch 139/300\n",
      "804/804 [==============================] - 0s 424us/step - loss: 0.5392 - accuracy: 0.7377\n",
      "Epoch 140/300\n",
      "804/804 [==============================] - 0s 426us/step - loss: 0.5406 - accuracy: 0.7342\n",
      "Epoch 141/300\n",
      "804/804 [==============================] - 0s 425us/step - loss: 0.5387 - accuracy: 0.7363\n",
      "Epoch 142/300\n",
      "804/804 [==============================] - 0s 424us/step - loss: 0.5364 - accuracy: 0.7403\n",
      "Epoch 143/300\n",
      "804/804 [==============================] - 0s 427us/step - loss: 0.5428 - accuracy: 0.7333\n",
      "Epoch 144/300\n",
      "804/804 [==============================] - 0s 417us/step - loss: 0.5399 - accuracy: 0.7314\n",
      "Epoch 145/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5405 - accuracy: 0.7332\n",
      "Epoch 146/300\n",
      "804/804 [==============================] - 0s 423us/step - loss: 0.5416 - accuracy: 0.7360\n",
      "Epoch 147/300\n",
      "804/804 [==============================] - 0s 416us/step - loss: 0.5411 - accuracy: 0.7364\n",
      "Epoch 148/300\n",
      "804/804 [==============================] - 0s 424us/step - loss: 0.5404 - accuracy: 0.7327\n",
      "Epoch 149/300\n",
      "804/804 [==============================] - 0s 426us/step - loss: 0.5413 - accuracy: 0.7350\n",
      "Epoch 150/300\n",
      "804/804 [==============================] - 0s 430us/step - loss: 0.5399 - accuracy: 0.7364\n",
      "Epoch 151/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5432 - accuracy: 0.7348\n",
      "Epoch 152/300\n",
      "804/804 [==============================] - 0s 422us/step - loss: 0.5388 - accuracy: 0.7388\n",
      "Epoch 153/300\n",
      "804/804 [==============================] - 0s 404us/step - loss: 0.5399 - accuracy: 0.7348\n",
      "Epoch 154/300\n",
      "804/804 [==============================] - 0s 413us/step - loss: 0.5389 - accuracy: 0.7370\n",
      "Epoch 155/300\n",
      "804/804 [==============================] - 0s 404us/step - loss: 0.5386 - accuracy: 0.7385\n",
      "Epoch 156/300\n",
      "804/804 [==============================] - 0s 392us/step - loss: 0.5376 - accuracy: 0.7386\n",
      "Epoch 157/300\n",
      "804/804 [==============================] - 0s 414us/step - loss: 0.5428 - accuracy: 0.7329\n",
      "Epoch 158/300\n",
      "804/804 [==============================] - 0s 413us/step - loss: 0.5416 - accuracy: 0.7335\n",
      "Epoch 159/300\n",
      "804/804 [==============================] - 0s 400us/step - loss: 0.5374 - accuracy: 0.7380\n",
      "Epoch 160/300\n",
      "804/804 [==============================] - 0s 392us/step - loss: 0.5368 - accuracy: 0.7414\n",
      "Epoch 161/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5409 - accuracy: 0.7359\n",
      "Epoch 162/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5372 - accuracy: 0.7379\n",
      "Epoch 163/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5413 - accuracy: 0.7382\n",
      "Epoch 164/300\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5398 - accuracy: 0.7364\n",
      "Epoch 165/300\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5395 - accuracy: 0.7356\n",
      "Epoch 166/300\n",
      "804/804 [==============================] - 0s 409us/step - loss: 0.5387 - accuracy: 0.7357\n",
      "Epoch 167/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5333 - accuracy: 0.7395\n",
      "Epoch 168/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5428 - accuracy: 0.7344\n",
      "Epoch 169/300\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5436 - accuracy: 0.7358\n",
      "Epoch 170/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5442 - accuracy: 0.7307\n",
      "Epoch 171/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5382 - accuracy: 0.7382\n",
      "Epoch 172/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5360 - accuracy: 0.7397\n",
      "Epoch 173/300\n",
      "804/804 [==============================] - 0s 407us/step - loss: 0.5372 - accuracy: 0.7358\n",
      "Epoch 174/300\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5387 - accuracy: 0.7347\n",
      "Epoch 175/300\n",
      "804/804 [==============================] - 0s 404us/step - loss: 0.5367 - accuracy: 0.7393\n",
      "Epoch 176/300\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5396 - accuracy: 0.7361\n",
      "Epoch 177/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5356 - accuracy: 0.7385\n",
      "Epoch 178/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5418 - accuracy: 0.7355\n",
      "Epoch 179/300\n",
      "804/804 [==============================] - 0s 409us/step - loss: 0.5371 - accuracy: 0.7367\n",
      "Epoch 180/300\n",
      "804/804 [==============================] - 0s 404us/step - loss: 0.5410 - accuracy: 0.7352\n",
      "Epoch 181/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5414 - accuracy: 0.7343\n",
      "Epoch 182/300\n",
      "804/804 [==============================] - 0s 404us/step - loss: 0.5380 - accuracy: 0.7386\n",
      "Epoch 183/300\n",
      "804/804 [==============================] - 0s 409us/step - loss: 0.5398 - accuracy: 0.7325\n",
      "Epoch 184/300\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5417 - accuracy: 0.7350\n",
      "Epoch 185/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5425 - accuracy: 0.7318\n",
      "Epoch 186/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5405 - accuracy: 0.7348\n",
      "Epoch 187/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5404 - accuracy: 0.7359\n",
      "Epoch 188/300\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5401 - accuracy: 0.7359\n",
      "Epoch 189/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5379 - accuracy: 0.7381\n",
      "Epoch 190/300\n",
      "804/804 [==============================] - 0s 400us/step - loss: 0.5440 - accuracy: 0.7328\n",
      "Epoch 191/300\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5338 - accuracy: 0.7400\n",
      "Epoch 192/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5393 - accuracy: 0.7386\n",
      "Epoch 193/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5421 - accuracy: 0.7342\n",
      "Epoch 194/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5396 - accuracy: 0.7322\n",
      "Epoch 195/300\n",
      "804/804 [==============================] - 0s 392us/step - loss: 0.5442 - accuracy: 0.7348\n",
      "Epoch 196/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5404 - accuracy: 0.7364\n",
      "Epoch 197/300\n",
      "804/804 [==============================] - 0s 389us/step - loss: 0.5400 - accuracy: 0.7346\n",
      "Epoch 198/300\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5399 - accuracy: 0.7366\n",
      "Epoch 199/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5427 - accuracy: 0.7332\n",
      "Epoch 200/300\n",
      "804/804 [==============================] - 0s 403us/step - loss: 0.5432 - accuracy: 0.7313\n",
      "Epoch 201/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5424 - accuracy: 0.7322\n",
      "Epoch 202/300\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5380 - accuracy: 0.7373\n",
      "Epoch 203/300\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5441 - accuracy: 0.7305\n",
      "Epoch 204/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5314 - accuracy: 0.7422\n",
      "Epoch 205/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5326 - accuracy: 0.7422\n",
      "Epoch 206/300\n",
      "804/804 [==============================] - 0s 401us/step - loss: 0.5360 - accuracy: 0.7376\n",
      "Epoch 207/300\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5349 - accuracy: 0.7389\n",
      "Epoch 208/300\n",
      "804/804 [==============================] - 0s 410us/step - loss: 0.5434 - accuracy: 0.7316\n",
      "Epoch 209/300\n",
      "804/804 [==============================] - 0s 392us/step - loss: 0.5355 - accuracy: 0.7372\n",
      "Epoch 210/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5319 - accuracy: 0.7415\n",
      "Epoch 211/300\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5355 - accuracy: 0.7428\n",
      "Epoch 212/300\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5370 - accuracy: 0.7403\n",
      "Epoch 213/300\n",
      "804/804 [==============================] - 0s 403us/step - loss: 0.5439 - accuracy: 0.7337\n",
      "Epoch 214/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5379 - accuracy: 0.7361\n",
      "Epoch 215/300\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5399 - accuracy: 0.7374\n",
      "Epoch 216/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5384 - accuracy: 0.7361\n",
      "Epoch 217/300\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5424 - accuracy: 0.7304\n",
      "Epoch 218/300\n",
      "804/804 [==============================] - 0s 403us/step - loss: 0.5363 - accuracy: 0.7413\n",
      "Epoch 219/300\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5430 - accuracy: 0.7327\n",
      "Epoch 220/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5379 - accuracy: 0.7359\n",
      "Epoch 221/300\n",
      "804/804 [==============================] - 0s 403us/step - loss: 0.5376 - accuracy: 0.7396\n",
      "Epoch 222/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5430 - accuracy: 0.7328\n",
      "Epoch 223/300\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5417 - accuracy: 0.7353\n",
      "Epoch 224/300\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5406 - accuracy: 0.7342\n",
      "Epoch 225/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5356 - accuracy: 0.7402\n",
      "Epoch 226/300\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5435 - accuracy: 0.7325\n",
      "Epoch 227/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5414 - accuracy: 0.7327\n",
      "Epoch 228/300\n",
      "804/804 [==============================] - 0s 404us/step - loss: 0.5413 - accuracy: 0.7343\n",
      "Epoch 229/300\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5425 - accuracy: 0.7323\n",
      "Epoch 230/300\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5435 - accuracy: 0.7297\n",
      "Epoch 231/300\n",
      "804/804 [==============================] - 0s 401us/step - loss: 0.5408 - accuracy: 0.7326\n",
      "Epoch 232/300\n",
      "804/804 [==============================] - 0s 402us/step - loss: 0.5401 - accuracy: 0.7364\n",
      "Epoch 233/300\n",
      "804/804 [==============================] - 0s 406us/step - loss: 0.5379 - accuracy: 0.7375\n",
      "Epoch 234/300\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5408 - accuracy: 0.7373\n",
      "Epoch 235/300\n",
      "804/804 [==============================] - 0s 404us/step - loss: 0.5396 - accuracy: 0.7360\n",
      "Epoch 236/300\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5359 - accuracy: 0.7411\n",
      "Epoch 237/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5401 - accuracy: 0.7337\n",
      "Epoch 238/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5395 - accuracy: 0.7343\n",
      "Epoch 239/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5414 - accuracy: 0.7336\n",
      "Epoch 240/300\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5346 - accuracy: 0.7370\n",
      "Epoch 241/300\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5389 - accuracy: 0.7364\n",
      "Epoch 242/300\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5348 - accuracy: 0.7389\n",
      "Epoch 243/300\n",
      "804/804 [==============================] - 0s 404us/step - loss: 0.5367 - accuracy: 0.7349\n",
      "Epoch 244/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5363 - accuracy: 0.7372\n",
      "Epoch 245/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5392 - accuracy: 0.7346\n",
      "Epoch 246/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5382 - accuracy: 0.7353\n",
      "Epoch 247/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5380 - accuracy: 0.7384\n",
      "Epoch 248/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5413 - accuracy: 0.7354\n",
      "Epoch 249/300\n",
      "804/804 [==============================] - 0s 406us/step - loss: 0.5396 - accuracy: 0.7372\n",
      "Epoch 250/300\n",
      "804/804 [==============================] - 0s 419us/step - loss: 0.5395 - accuracy: 0.7353\n",
      "Epoch 251/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5346 - accuracy: 0.7398\n",
      "Epoch 252/300\n",
      "804/804 [==============================] - 0s 408us/step - loss: 0.5376 - accuracy: 0.7334\n",
      "Epoch 253/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5401 - accuracy: 0.7352\n",
      "Epoch 254/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5372 - accuracy: 0.7383\n",
      "Epoch 255/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5341 - accuracy: 0.7373\n",
      "Epoch 256/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5378 - accuracy: 0.7368\n",
      "Epoch 257/300\n",
      "804/804 [==============================] - 0s 401us/step - loss: 0.5400 - accuracy: 0.7348\n",
      "Epoch 258/300\n",
      "804/804 [==============================] - 0s 404us/step - loss: 0.5341 - accuracy: 0.7395\n",
      "Epoch 259/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5398 - accuracy: 0.7346\n",
      "Epoch 260/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5336 - accuracy: 0.7398\n",
      "Epoch 261/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5308 - accuracy: 0.7416\n",
      "Epoch 262/300\n",
      "804/804 [==============================] - 0s 403us/step - loss: 0.5401 - accuracy: 0.7344\n",
      "Epoch 263/300\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5336 - accuracy: 0.7401\n",
      "Epoch 264/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5336 - accuracy: 0.7385\n",
      "Epoch 265/300\n",
      "804/804 [==============================] - 0s 404us/step - loss: 0.5416 - accuracy: 0.7356\n",
      "Epoch 266/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5353 - accuracy: 0.7410\n",
      "Epoch 267/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5347 - accuracy: 0.7401\n",
      "Epoch 268/300\n",
      "804/804 [==============================] - 0s 403us/step - loss: 0.5394 - accuracy: 0.7348\n",
      "Epoch 269/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5352 - accuracy: 0.7409\n",
      "Epoch 270/300\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5395 - accuracy: 0.7337\n",
      "Epoch 271/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5434 - accuracy: 0.7314\n",
      "Epoch 272/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5340 - accuracy: 0.7390\n",
      "Epoch 273/300\n",
      "804/804 [==============================] - 0s 403us/step - loss: 0.5418 - accuracy: 0.7361\n",
      "Epoch 274/300\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5428 - accuracy: 0.7331\n",
      "Epoch 275/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5418 - accuracy: 0.7351\n",
      "Epoch 276/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5412 - accuracy: 0.7340\n",
      "Epoch 277/300\n",
      "804/804 [==============================] - 0s 406us/step - loss: 0.5387 - accuracy: 0.7352\n",
      "Epoch 278/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5353 - accuracy: 0.7408\n",
      "Epoch 279/300\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5387 - accuracy: 0.7356\n",
      "Epoch 280/300\n",
      "804/804 [==============================] - 0s 411us/step - loss: 0.5346 - accuracy: 0.7420\n",
      "Epoch 281/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5376 - accuracy: 0.7372\n",
      "Epoch 282/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5380 - accuracy: 0.7344\n",
      "Epoch 283/300\n",
      "804/804 [==============================] - 0s 404us/step - loss: 0.5293 - accuracy: 0.7444\n",
      "Epoch 284/300\n",
      "804/804 [==============================] - 0s 403us/step - loss: 0.5393 - accuracy: 0.7362\n",
      "Epoch 285/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5366 - accuracy: 0.7392\n",
      "Epoch 286/300\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5393 - accuracy: 0.7375\n",
      "Epoch 287/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5415 - accuracy: 0.7339\n",
      "Epoch 288/300\n",
      "804/804 [==============================] - 0s 401us/step - loss: 0.5361 - accuracy: 0.7371\n",
      "Epoch 289/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5367 - accuracy: 0.7356\n",
      "Epoch 290/300\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5361 - accuracy: 0.7373\n",
      "Epoch 291/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5324 - accuracy: 0.7399\n",
      "Epoch 292/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5411 - accuracy: 0.7325\n",
      "Epoch 293/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5363 - accuracy: 0.7377\n",
      "Epoch 294/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5373 - accuracy: 0.7359\n",
      "Epoch 295/300\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5365 - accuracy: 0.7374\n",
      "Epoch 296/300\n",
      "804/804 [==============================] - 0s 406us/step - loss: 0.5404 - accuracy: 0.7303\n",
      "Epoch 297/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5441 - accuracy: 0.7301\n",
      "Epoch 298/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5378 - accuracy: 0.7355\n",
      "Epoch 299/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5352 - accuracy: 0.7410\n",
      "Epoch 300/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5395 - accuracy: 0.7347\n"
     ]
    }
   ],
   "source": [
    "# Increasing number of epochs to 300\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "268/268 - 0s - loss: 0.5692 - accuracy: 0.7377\n",
      "Loss: 0.5692165493965149, Accuracy: 0.7377259731292725\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "source": [
    "Increase the number of hidden nodes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_6 (Dense)              (None, 90)                3780      \n_________________________________________________________________\ndense_7 (Dense)              (None, 40)                3640      \n_________________________________________________________________\ndense_8 (Dense)              (None, 1)                 41        \n=================================================================\nTotal params: 7,461\nTrainable params: 7,461\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "num_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1= 90\n",
    "nn = tf.keras.models.Sequential()\n",
    "hidden_nodes_layer2 = 40\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=num_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 1s 410us/step - loss: 0.5916 - accuracy: 0.7096\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5613 - accuracy: 0.7268\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5588 - accuracy: 0.7275\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5580 - accuracy: 0.7266\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 0s 385us/step - loss: 0.5549 - accuracy: 0.7284\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 0s 386us/step - loss: 0.5604 - accuracy: 0.7248\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5561 - accuracy: 0.7274\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 0s 386us/step - loss: 0.5516 - accuracy: 0.7322\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 0s 387us/step - loss: 0.5583 - accuracy: 0.7243\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 0s 388us/step - loss: 0.5504 - accuracy: 0.7290\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 0s 388us/step - loss: 0.5529 - accuracy: 0.7286\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 0s 383us/step - loss: 0.5499 - accuracy: 0.7331\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 0s 385us/step - loss: 0.5539 - accuracy: 0.7202\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 0s 388us/step - loss: 0.5485 - accuracy: 0.7341\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 0s 386us/step - loss: 0.5529 - accuracy: 0.7318\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 0s 387us/step - loss: 0.5507 - accuracy: 0.7324\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 0s 389us/step - loss: 0.5498 - accuracy: 0.7324\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 0s 386us/step - loss: 0.5496 - accuracy: 0.7321\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 0s 386us/step - loss: 0.5504 - accuracy: 0.7309\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5518 - accuracy: 0.7288\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 0s 389us/step - loss: 0.5506 - accuracy: 0.7308\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 0s 388us/step - loss: 0.5493 - accuracy: 0.7320\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 0s 389us/step - loss: 0.5470 - accuracy: 0.7353\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 0s 413us/step - loss: 0.5497 - accuracy: 0.7301\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5502 - accuracy: 0.7302\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 0s 402us/step - loss: 0.5452 - accuracy: 0.7316\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5501 - accuracy: 0.7309\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 0s 401us/step - loss: 0.5520 - accuracy: 0.7295\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5456 - accuracy: 0.7355\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 0s 392us/step - loss: 0.5507 - accuracy: 0.7293\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5539 - accuracy: 0.7288\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 0s 387us/step - loss: 0.5437 - accuracy: 0.7367\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5457 - accuracy: 0.7328\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 0s 386us/step - loss: 0.5493 - accuracy: 0.7301\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 0s 386us/step - loss: 0.5494 - accuracy: 0.7299\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 0s 388us/step - loss: 0.5425 - accuracy: 0.7374\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 0s 388us/step - loss: 0.5502 - accuracy: 0.7282\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5460 - accuracy: 0.7323\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5515 - accuracy: 0.7278\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 0s 389us/step - loss: 0.5448 - accuracy: 0.7337\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 0s 385us/step - loss: 0.5422 - accuracy: 0.7373\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5424 - accuracy: 0.7392\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5461 - accuracy: 0.7359\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 0s 386us/step - loss: 0.5430 - accuracy: 0.7342\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 0s 386us/step - loss: 0.5430 - accuracy: 0.7340\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 0s 386us/step - loss: 0.5475 - accuracy: 0.7301\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 0s 387us/step - loss: 0.5409 - accuracy: 0.7391\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 0s 388us/step - loss: 0.5432 - accuracy: 0.7364\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 0s 392us/step - loss: 0.5430 - accuracy: 0.7348\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5428 - accuracy: 0.7360\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5436 - accuracy: 0.7329\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5468 - accuracy: 0.7309\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 0s 388us/step - loss: 0.5448 - accuracy: 0.7337\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5426 - accuracy: 0.7328\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 0s 388us/step - loss: 0.5433 - accuracy: 0.7359\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5448 - accuracy: 0.7345\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5417 - accuracy: 0.7381\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 0s 401us/step - loss: 0.5469 - accuracy: 0.7281\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5414 - accuracy: 0.7366\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 0s 386us/step - loss: 0.5413 - accuracy: 0.7388\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5412 - accuracy: 0.7362\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 0s 389us/step - loss: 0.5434 - accuracy: 0.7344\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 0s 388us/step - loss: 0.5412 - accuracy: 0.7356\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5466 - accuracy: 0.7320\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 0s 389us/step - loss: 0.5431 - accuracy: 0.7344\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5381 - accuracy: 0.7389\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 0s 386us/step - loss: 0.5464 - accuracy: 0.7302\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 0s 414us/step - loss: 0.5446 - accuracy: 0.7346\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 0s 405us/step - loss: 0.5429 - accuracy: 0.7349\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 0s 421us/step - loss: 0.5424 - accuracy: 0.7330\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 0s 410us/step - loss: 0.5417 - accuracy: 0.7358\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5418 - accuracy: 0.7361\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 0s 412us/step - loss: 0.5428 - accuracy: 0.7356\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 0s 409us/step - loss: 0.5407 - accuracy: 0.7377\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 0s 415us/step - loss: 0.5410 - accuracy: 0.7357\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 0s 414us/step - loss: 0.5433 - accuracy: 0.7324\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 0s 418us/step - loss: 0.5420 - accuracy: 0.7340\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5423 - accuracy: 0.7358\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5418 - accuracy: 0.7355\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 0s 409us/step - loss: 0.5378 - accuracy: 0.7375\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 0s 423us/step - loss: 0.5447 - accuracy: 0.7335\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 0s 411us/step - loss: 0.5416 - accuracy: 0.7374\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 0s 423us/step - loss: 0.5463 - accuracy: 0.7348\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 0s 414us/step - loss: 0.5426 - accuracy: 0.7353\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 0s 409us/step - loss: 0.5420 - accuracy: 0.7360\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 0s 404us/step - loss: 0.5438 - accuracy: 0.7333\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 0s 401us/step - loss: 0.5436 - accuracy: 0.7309\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 0s 404us/step - loss: 0.5390 - accuracy: 0.7358\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5465 - accuracy: 0.7330\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5496 - accuracy: 0.7270\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5388 - accuracy: 0.7381\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5389 - accuracy: 0.7350\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5385 - accuracy: 0.7395\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5371 - accuracy: 0.7412\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5454 - accuracy: 0.7296\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5430 - accuracy: 0.7347\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5412 - accuracy: 0.7347\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5432 - accuracy: 0.7353\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5396 - accuracy: 0.7387\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 0s 389us/step - loss: 0.5420 - accuracy: 0.7348\n"
     ]
    }
   ],
   "source": [
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "268/268 - 0s - loss: 0.5575 - accuracy: 0.7395\n",
      "Loss: 0.5574780106544495, Accuracy: 0.7394751906394958\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "source": [
    "Combining both modifications"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_9 (Dense)              (None, 90)                3780      \n_________________________________________________________________\ndense_10 (Dense)             (None, 40)                3640      \n_________________________________________________________________\ndense_11 (Dense)             (None, 1)                 41        \n=================================================================\nTotal params: 7,461\nTrainable params: 7,461\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "num_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1= 90\n",
    "nn = tf.keras.models.Sequential()\n",
    "hidden_nodes_layer2 = 40\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=num_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "- 0s 441us/step - loss: 0.5429 - accuracy: 0.7327\n",
      "Epoch 111/300\n",
      "804/804 [==============================] - 0s 406us/step - loss: 0.5416 - accuracy: 0.7369\n",
      "Epoch 112/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5418 - accuracy: 0.7342\n",
      "Epoch 113/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5422 - accuracy: 0.7329\n",
      "Epoch 114/300\n",
      "804/804 [==============================] - 0s 406us/step - loss: 0.5385 - accuracy: 0.7388\n",
      "Epoch 115/300\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5414 - accuracy: 0.7349\n",
      "Epoch 116/300\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5421 - accuracy: 0.7376\n",
      "Epoch 117/300\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5388 - accuracy: 0.7374\n",
      "Epoch 118/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5410 - accuracy: 0.7334\n",
      "Epoch 119/300\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5392 - accuracy: 0.7374\n",
      "Epoch 120/300\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5362 - accuracy: 0.7394\n",
      "Epoch 121/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5411 - accuracy: 0.7351\n",
      "Epoch 122/300\n",
      "804/804 [==============================] - 0s 387us/step - loss: 0.5387 - accuracy: 0.7353\n",
      "Epoch 123/300\n",
      "804/804 [==============================] - 0s 392us/step - loss: 0.5407 - accuracy: 0.7346\n",
      "Epoch 124/300\n",
      "804/804 [==============================] - 0s 411us/step - loss: 0.5392 - accuracy: 0.7357\n",
      "Epoch 125/300\n",
      "804/804 [==============================] - 0s 416us/step - loss: 0.5392 - accuracy: 0.7378\n",
      "Epoch 126/300\n",
      "804/804 [==============================] - 0s 428us/step - loss: 0.5360 - accuracy: 0.7373\n",
      "Epoch 127/300\n",
      "804/804 [==============================] - 0s 419us/step - loss: 0.5395 - accuracy: 0.7366\n",
      "Epoch 128/300\n",
      "804/804 [==============================] - 0s 458us/step - loss: 0.5384 - accuracy: 0.7358\n",
      "Epoch 129/300\n",
      "804/804 [==============================] - 0s 424us/step - loss: 0.5389 - accuracy: 0.7361\n",
      "Epoch 130/300\n",
      "804/804 [==============================] - 0s 433us/step - loss: 0.5387 - accuracy: 0.7365\n",
      "Epoch 131/300\n",
      "804/804 [==============================] - 0s 424us/step - loss: 0.5421 - accuracy: 0.7353\n",
      "Epoch 132/300\n",
      "804/804 [==============================] - 0s 454us/step - loss: 0.5394 - accuracy: 0.7341\n",
      "Epoch 133/300\n",
      "804/804 [==============================] - 0s 403us/step - loss: 0.5415 - accuracy: 0.7325\n",
      "Epoch 134/300\n",
      "804/804 [==============================] - 0s 428us/step - loss: 0.5399 - accuracy: 0.7340\n",
      "Epoch 135/300\n",
      "804/804 [==============================] - 0s 392us/step - loss: 0.5351 - accuracy: 0.7388\n",
      "Epoch 136/300\n",
      "804/804 [==============================] - 0s 401us/step - loss: 0.5324 - accuracy: 0.7415\n",
      "Epoch 137/300\n",
      "804/804 [==============================] - 0s 415us/step - loss: 0.5388 - accuracy: 0.7358\n",
      "Epoch 138/300\n",
      "804/804 [==============================] - 0s 410us/step - loss: 0.5383 - accuracy: 0.7365\n",
      "Epoch 139/300\n",
      "804/804 [==============================] - 0s 423us/step - loss: 0.5412 - accuracy: 0.7339\n",
      "Epoch 140/300\n",
      "804/804 [==============================] - 0s 424us/step - loss: 0.5357 - accuracy: 0.7394\n",
      "Epoch 141/300\n",
      "804/804 [==============================] - 0s 416us/step - loss: 0.5375 - accuracy: 0.7369\n",
      "Epoch 142/300\n",
      "804/804 [==============================] - 0s 420us/step - loss: 0.5407 - accuracy: 0.7340\n",
      "Epoch 143/300\n",
      "804/804 [==============================] - 0s 422us/step - loss: 0.5430 - accuracy: 0.7330\n",
      "Epoch 144/300\n",
      "804/804 [==============================] - 0s 418us/step - loss: 0.5410 - accuracy: 0.7346\n",
      "Epoch 145/300\n",
      "804/804 [==============================] - 0s 408us/step - loss: 0.5435 - accuracy: 0.7305\n",
      "Epoch 146/300\n",
      "804/804 [==============================] - 0s 409us/step - loss: 0.5423 - accuracy: 0.7342\n",
      "Epoch 147/300\n",
      "804/804 [==============================] - 0s 407us/step - loss: 0.5383 - accuracy: 0.7386\n",
      "Epoch 148/300\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5347 - accuracy: 0.7402\n",
      "Epoch 149/300\n",
      "804/804 [==============================] - 0s 389us/step - loss: 0.5388 - accuracy: 0.7355\n",
      "Epoch 150/300\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5344 - accuracy: 0.7401\n",
      "Epoch 151/300\n",
      "804/804 [==============================] - 0s 401us/step - loss: 0.5365 - accuracy: 0.7373\n",
      "Epoch 152/300\n",
      "804/804 [==============================] - 0s 405us/step - loss: 0.5383 - accuracy: 0.7360\n",
      "Epoch 153/300\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5314 - accuracy: 0.7443\n",
      "Epoch 154/300\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5372 - accuracy: 0.7368\n",
      "Epoch 155/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5350 - accuracy: 0.7404\n",
      "Epoch 156/300\n",
      "804/804 [==============================] - 0s 403us/step - loss: 0.5348 - accuracy: 0.7404\n",
      "Epoch 157/300\n",
      "804/804 [==============================] - 0s 408us/step - loss: 0.5376 - accuracy: 0.7391\n",
      "Epoch 158/300\n",
      "804/804 [==============================] - 0s 423us/step - loss: 0.5407 - accuracy: 0.7360\n",
      "Epoch 159/300\n",
      "804/804 [==============================] - 0s 462us/step - loss: 0.5390 - accuracy: 0.7363\n",
      "Epoch 160/300\n",
      "804/804 [==============================] - 0s 429us/step - loss: 0.5387 - accuracy: 0.7359\n",
      "Epoch 161/300\n",
      "804/804 [==============================] - 0s 514us/step - loss: 0.5355 - accuracy: 0.7395\n",
      "Epoch 162/300\n",
      "804/804 [==============================] - 0s 450us/step - loss: 0.5444 - accuracy: 0.7323\n",
      "Epoch 163/300\n",
      "804/804 [==============================] - 0s 460us/step - loss: 0.5356 - accuracy: 0.7398\n",
      "Epoch 164/300\n",
      "804/804 [==============================] - 0s 429us/step - loss: 0.5386 - accuracy: 0.7383\n",
      "Epoch 165/300\n",
      "804/804 [==============================] - 0s 412us/step - loss: 0.5380 - accuracy: 0.7385\n",
      "Epoch 166/300\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5430 - accuracy: 0.7318\n",
      "Epoch 167/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5412 - accuracy: 0.7329\n",
      "Epoch 168/300\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5436 - accuracy: 0.7300\n",
      "Epoch 169/300\n",
      "804/804 [==============================] - 0s 415us/step - loss: 0.5376 - accuracy: 0.7368\n",
      "Epoch 170/300\n",
      "804/804 [==============================] - 0s 400us/step - loss: 0.5420 - accuracy: 0.7338\n",
      "Epoch 171/300\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5356 - accuracy: 0.7401\n",
      "Epoch 172/300\n",
      "804/804 [==============================] - 0s 388us/step - loss: 0.5377 - accuracy: 0.7371\n",
      "Epoch 173/300\n",
      "804/804 [==============================] - 0s 388us/step - loss: 0.5411 - accuracy: 0.7356\n",
      "Epoch 174/300\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5378 - accuracy: 0.7363\n",
      "Epoch 175/300\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5407 - accuracy: 0.7344\n",
      "Epoch 176/300\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5348 - accuracy: 0.7378\n",
      "Epoch 177/300\n",
      "804/804 [==============================] - 0s 400us/step - loss: 0.5395 - accuracy: 0.7382\n",
      "Epoch 178/300\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5405 - accuracy: 0.7352\n",
      "Epoch 179/300\n",
      "804/804 [==============================] - 0s 408us/step - loss: 0.5373 - accuracy: 0.7365\n",
      "Epoch 180/300\n",
      "804/804 [==============================] - 0s 409us/step - loss: 0.5428 - accuracy: 0.7320\n",
      "Epoch 181/300\n",
      "804/804 [==============================] - 0s 409us/step - loss: 0.5361 - accuracy: 0.7378\n",
      "Epoch 182/300\n",
      "804/804 [==============================] - 0s 426us/step - loss: 0.5374 - accuracy: 0.7360\n",
      "Epoch 183/300\n",
      "804/804 [==============================] - 1s 638us/step - loss: 0.5356 - accuracy: 0.7400\n",
      "Epoch 184/300\n",
      "804/804 [==============================] - 1s 793us/step - loss: 0.5391 - accuracy: 0.7365\n",
      "Epoch 185/300\n",
      "804/804 [==============================] - 1s 674us/step - loss: 0.5390 - accuracy: 0.7330\n",
      "Epoch 186/300\n",
      "804/804 [==============================] - 0s 474us/step - loss: 0.5394 - accuracy: 0.7346\n",
      "Epoch 187/300\n",
      "804/804 [==============================] - 0s 462us/step - loss: 0.5425 - accuracy: 0.7340\n",
      "Epoch 188/300\n",
      "804/804 [==============================] - 0s 419us/step - loss: 0.5347 - accuracy: 0.7379\n",
      "Epoch 189/300\n",
      "804/804 [==============================] - 0s 411us/step - loss: 0.5390 - accuracy: 0.7363\n",
      "Epoch 190/300\n",
      "804/804 [==============================] - 0s 401us/step - loss: 0.5438 - accuracy: 0.7337\n",
      "Epoch 191/300\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5386 - accuracy: 0.7365\n",
      "Epoch 192/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5392 - accuracy: 0.7362\n",
      "Epoch 193/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5397 - accuracy: 0.7360\n",
      "Epoch 194/300\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5342 - accuracy: 0.7380\n",
      "Epoch 195/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5371 - accuracy: 0.7387\n",
      "Epoch 196/300\n",
      "804/804 [==============================] - 0s 419us/step - loss: 0.5404 - accuracy: 0.7345\n",
      "Epoch 197/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5372 - accuracy: 0.7388\n",
      "Epoch 198/300\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5415 - accuracy: 0.7365\n",
      "Epoch 199/300\n",
      "804/804 [==============================] - 0s 413us/step - loss: 0.5433 - accuracy: 0.7328\n",
      "Epoch 200/300\n",
      "804/804 [==============================] - 0s 406us/step - loss: 0.5371 - accuracy: 0.7411\n",
      "Epoch 201/300\n",
      "804/804 [==============================] - 0s 403us/step - loss: 0.5335 - accuracy: 0.7395\n",
      "Epoch 202/300\n",
      "804/804 [==============================] - 0s 401us/step - loss: 0.5432 - accuracy: 0.7343\n",
      "Epoch 203/300\n",
      "804/804 [==============================] - 0s 417us/step - loss: 0.5375 - accuracy: 0.7352\n",
      "Epoch 204/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5365 - accuracy: 0.7372\n",
      "Epoch 205/300\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5414 - accuracy: 0.7345\n",
      "Epoch 206/300\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5383 - accuracy: 0.7359\n",
      "Epoch 207/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5371 - accuracy: 0.7389\n",
      "Epoch 208/300\n",
      "804/804 [==============================] - 0s 411us/step - loss: 0.5372 - accuracy: 0.7403\n",
      "Epoch 209/300\n",
      "804/804 [==============================] - 0s 402us/step - loss: 0.5395 - accuracy: 0.7360\n",
      "Epoch 210/300\n",
      "804/804 [==============================] - 0s 421us/step - loss: 0.5414 - accuracy: 0.7302\n",
      "Epoch 211/300\n",
      "804/804 [==============================] - 0s 406us/step - loss: 0.5397 - accuracy: 0.7376\n",
      "Epoch 212/300\n",
      "804/804 [==============================] - 0s 409us/step - loss: 0.5416 - accuracy: 0.7341\n",
      "Epoch 213/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5371 - accuracy: 0.7389\n",
      "Epoch 214/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5342 - accuracy: 0.7397\n",
      "Epoch 215/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5378 - accuracy: 0.7362\n",
      "Epoch 216/300\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5426 - accuracy: 0.7330\n",
      "Epoch 217/300\n",
      "804/804 [==============================] - 0s 403us/step - loss: 0.5407 - accuracy: 0.7353\n",
      "Epoch 218/300\n",
      "804/804 [==============================] - 0s 402us/step - loss: 0.5397 - accuracy: 0.7361\n",
      "Epoch 219/300\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5355 - accuracy: 0.7375\n",
      "Epoch 220/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5387 - accuracy: 0.7392\n",
      "Epoch 221/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5351 - accuracy: 0.7395\n",
      "Epoch 222/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5410 - accuracy: 0.7334\n",
      "Epoch 223/300\n",
      "804/804 [==============================] - 0s 392us/step - loss: 0.5407 - accuracy: 0.7339\n",
      "Epoch 224/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5356 - accuracy: 0.7385\n",
      "Epoch 225/300\n",
      "804/804 [==============================] - 0s 405us/step - loss: 0.5309 - accuracy: 0.7412\n",
      "Epoch 226/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5361 - accuracy: 0.7387\n",
      "Epoch 227/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5371 - accuracy: 0.7363\n",
      "Epoch 228/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5407 - accuracy: 0.7348\n",
      "Epoch 229/300\n",
      "804/804 [==============================] - 0s 389us/step - loss: 0.5422 - accuracy: 0.7332\n",
      "Epoch 230/300\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5383 - accuracy: 0.7358\n",
      "Epoch 231/300\n",
      "804/804 [==============================] - 0s 413us/step - loss: 0.5399 - accuracy: 0.7363\n",
      "Epoch 232/300\n",
      "804/804 [==============================] - 0s 400us/step - loss: 0.5426 - accuracy: 0.7351\n",
      "Epoch 233/300\n",
      "804/804 [==============================] - 0s 414us/step - loss: 0.5364 - accuracy: 0.7368\n",
      "Epoch 234/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5343 - accuracy: 0.7394\n",
      "Epoch 235/300\n",
      "804/804 [==============================] - 0s 408us/step - loss: 0.5382 - accuracy: 0.7373\n",
      "Epoch 236/300\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5374 - accuracy: 0.7370\n",
      "Epoch 237/300\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5374 - accuracy: 0.7373\n",
      "Epoch 238/300\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5365 - accuracy: 0.7376\n",
      "Epoch 239/300\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5339 - accuracy: 0.7389\n",
      "Epoch 240/300\n",
      "804/804 [==============================] - 0s 405us/step - loss: 0.5383 - accuracy: 0.7378\n",
      "Epoch 241/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5356 - accuracy: 0.7384\n",
      "Epoch 242/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5335 - accuracy: 0.7384\n",
      "Epoch 243/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5343 - accuracy: 0.7383\n",
      "Epoch 244/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5368 - accuracy: 0.7370\n",
      "Epoch 245/300\n",
      "804/804 [==============================] - 0s 402us/step - loss: 0.5372 - accuracy: 0.7374\n",
      "Epoch 246/300\n",
      "804/804 [==============================] - 0s 401us/step - loss: 0.5390 - accuracy: 0.7350\n",
      "Epoch 247/300\n",
      "804/804 [==============================] - 0s 406us/step - loss: 0.5379 - accuracy: 0.7376\n",
      "Epoch 248/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5367 - accuracy: 0.7379\n",
      "Epoch 249/300\n",
      "804/804 [==============================] - 0s 399us/step - loss: 0.5422 - accuracy: 0.7337\n",
      "Epoch 250/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5370 - accuracy: 0.7435\n",
      "Epoch 251/300\n",
      "804/804 [==============================] - 0s 403us/step - loss: 0.5271 - accuracy: 0.7452\n",
      "Epoch 252/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5353 - accuracy: 0.7412\n",
      "Epoch 253/300\n",
      "804/804 [==============================] - 0s 402us/step - loss: 0.5382 - accuracy: 0.7360\n",
      "Epoch 254/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5424 - accuracy: 0.7347\n",
      "Epoch 255/300\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5344 - accuracy: 0.7397\n",
      "Epoch 256/300\n",
      "804/804 [==============================] - 0s 389us/step - loss: 0.5427 - accuracy: 0.7307\n",
      "Epoch 257/300\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5368 - accuracy: 0.7395\n",
      "Epoch 258/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5365 - accuracy: 0.7389\n",
      "Epoch 259/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5329 - accuracy: 0.7391\n",
      "Epoch 260/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5399 - accuracy: 0.7353\n",
      "Epoch 261/300\n",
      "804/804 [==============================] - 0s 400us/step - loss: 0.5327 - accuracy: 0.7428\n",
      "Epoch 262/300\n",
      "804/804 [==============================] - 0s 389us/step - loss: 0.5353 - accuracy: 0.7390\n",
      "Epoch 263/300\n",
      "804/804 [==============================] - 0s 388us/step - loss: 0.5372 - accuracy: 0.7374\n",
      "Epoch 264/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5371 - accuracy: 0.7395\n",
      "Epoch 265/300\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5386 - accuracy: 0.7367\n",
      "Epoch 266/300\n",
      "804/804 [==============================] - 0s 392us/step - loss: 0.5371 - accuracy: 0.7427\n",
      "Epoch 267/300\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5368 - accuracy: 0.7382\n",
      "Epoch 268/300\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5331 - accuracy: 0.7432\n",
      "Epoch 269/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5398 - accuracy: 0.7353\n",
      "Epoch 270/300\n",
      "804/804 [==============================] - 0s 403us/step - loss: 0.5415 - accuracy: 0.7350\n",
      "Epoch 271/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5356 - accuracy: 0.7375\n",
      "Epoch 272/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5393 - accuracy: 0.7327\n",
      "Epoch 273/300\n",
      "804/804 [==============================] - 0s 392us/step - loss: 0.5370 - accuracy: 0.7369\n",
      "Epoch 274/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5357 - accuracy: 0.7379\n",
      "Epoch 275/300\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5437 - accuracy: 0.7307\n",
      "Epoch 276/300\n",
      "804/804 [==============================] - 0s 404us/step - loss: 0.5370 - accuracy: 0.7369\n",
      "Epoch 277/300\n",
      "804/804 [==============================] - 0s 404us/step - loss: 0.5380 - accuracy: 0.7364\n",
      "Epoch 278/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5360 - accuracy: 0.7418\n",
      "Epoch 279/300\n",
      "804/804 [==============================] - 0s 390us/step - loss: 0.5402 - accuracy: 0.7355\n",
      "Epoch 280/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5426 - accuracy: 0.7320\n",
      "Epoch 281/300\n",
      "804/804 [==============================] - 0s 398us/step - loss: 0.5362 - accuracy: 0.7374\n",
      "Epoch 282/300\n",
      "804/804 [==============================] - 0s 406us/step - loss: 0.5341 - accuracy: 0.7387\n",
      "Epoch 283/300\n",
      "804/804 [==============================] - 0s 400us/step - loss: 0.5362 - accuracy: 0.7375\n",
      "Epoch 284/300\n",
      "804/804 [==============================] - 0s 403us/step - loss: 0.5357 - accuracy: 0.7373\n",
      "Epoch 285/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5378 - accuracy: 0.7355\n",
      "Epoch 286/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5349 - accuracy: 0.7403\n",
      "Epoch 287/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5375 - accuracy: 0.7391\n",
      "Epoch 288/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5363 - accuracy: 0.7378\n",
      "Epoch 289/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5415 - accuracy: 0.7336\n",
      "Epoch 290/300\n",
      "804/804 [==============================] - 0s 391us/step - loss: 0.5385 - accuracy: 0.7360\n",
      "Epoch 291/300\n",
      "804/804 [==============================] - 0s 394us/step - loss: 0.5396 - accuracy: 0.7366\n",
      "Epoch 292/300\n",
      "804/804 [==============================] - 0s 403us/step - loss: 0.5330 - accuracy: 0.7416\n",
      "Epoch 293/300\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5361 - accuracy: 0.7374\n",
      "Epoch 294/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5368 - accuracy: 0.7347\n",
      "Epoch 295/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5394 - accuracy: 0.7367\n",
      "Epoch 296/300\n",
      "804/804 [==============================] - 0s 396us/step - loss: 0.5414 - accuracy: 0.7322\n",
      "Epoch 297/300\n",
      "804/804 [==============================] - 0s 397us/step - loss: 0.5342 - accuracy: 0.7378\n",
      "Epoch 298/300\n",
      "804/804 [==============================] - 0s 395us/step - loss: 0.5418 - accuracy: 0.7329\n",
      "Epoch 299/300\n",
      "804/804 [==============================] - 0s 401us/step - loss: 0.5369 - accuracy: 0.7383\n",
      "Epoch 300/300\n",
      "804/804 [==============================] - 0s 393us/step - loss: 0.5351 - accuracy: 0.7403\n"
     ]
    }
   ],
   "source": [
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "268/268 - 0s - loss: 0.5817 - accuracy: 0.7377\n",
      "Loss: 0.581656277179718, Accuracy: 0.7377259731292725\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"262.19625pt\" version=\"1.1\" viewBox=\"0 0 447.8125 262.19625\" width=\"447.8125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-05-16T18:17:55.116585</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 262.19625 \r\nL 447.8125 262.19625 \r\nL 447.8125 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 56.50625 224.64 \r\nL 391.30625 224.64 \r\nL 391.30625 7.2 \r\nL 56.50625 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mec8eb4cbff\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"70.706493\" xlink:href=\"#mec8eb4cbff\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(67.525243 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"121.603422\" xlink:href=\"#mec8eb4cbff\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(115.240922 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"172.500352\" xlink:href=\"#mec8eb4cbff\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 100 -->\r\n      <g transform=\"translate(162.956602 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"223.397281\" xlink:href=\"#mec8eb4cbff\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 150 -->\r\n      <g transform=\"translate(213.853531 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"274.29421\" xlink:href=\"#mec8eb4cbff\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 200 -->\r\n      <g transform=\"translate(264.75046 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"325.191139\" xlink:href=\"#mec8eb4cbff\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 250 -->\r\n      <g transform=\"translate(315.647389 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"376.088068\" xlink:href=\"#mec8eb4cbff\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 300 -->\r\n      <g transform=\"translate(366.544318 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_8\">\r\n     <!-- Epoch -->\r\n     <g transform=\"translate(208.595313 252.916563)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 9.8125 72.90625 \r\nL 55.90625 72.90625 \r\nL 55.90625 64.59375 \r\nL 19.671875 64.59375 \r\nL 19.671875 43.015625 \r\nL 54.390625 43.015625 \r\nL 54.390625 34.71875 \r\nL 19.671875 34.71875 \r\nL 19.671875 8.296875 \r\nL 56.78125 8.296875 \r\nL 56.78125 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-69\"/>\r\n       <path d=\"M 18.109375 8.203125 \r\nL 18.109375 -20.796875 \r\nL 9.078125 -20.796875 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.390625 \r\nQ 20.953125 51.265625 25.265625 53.625 \r\nQ 29.59375 56 35.59375 56 \r\nQ 45.5625 56 51.78125 48.09375 \r\nQ 58.015625 40.1875 58.015625 27.296875 \r\nQ 58.015625 14.40625 51.78125 6.484375 \r\nQ 45.5625 -1.421875 35.59375 -1.421875 \r\nQ 29.59375 -1.421875 25.265625 0.953125 \r\nQ 20.953125 3.328125 18.109375 8.203125 \r\nz\r\nM 48.6875 27.296875 \r\nQ 48.6875 37.203125 44.609375 42.84375 \r\nQ 40.53125 48.484375 33.40625 48.484375 \r\nQ 26.265625 48.484375 22.1875 42.84375 \r\nQ 18.109375 37.203125 18.109375 27.296875 \r\nQ 18.109375 17.390625 22.1875 11.75 \r\nQ 26.265625 6.109375 33.40625 6.109375 \r\nQ 40.53125 6.109375 44.609375 11.75 \r\nQ 48.6875 17.390625 48.6875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-112\"/>\r\n       <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n       <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n       <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 75.984375 \r\nL 18.109375 75.984375 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-104\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-69\"/>\r\n      <use x=\"63.183594\" xlink:href=\"#DejaVuSans-112\"/>\r\n      <use x=\"126.660156\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"187.841797\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"242.822266\" xlink:href=\"#DejaVuSans-104\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_8\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"mc7955e441f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"56.50625\" xlink:href=\"#mc7955e441f\" y=\"202.661464\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.540 -->\r\n      <g transform=\"translate(20.878125 206.460682)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"56.50625\" xlink:href=\"#mc7955e441f\" y=\"177.713647\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.545 -->\r\n      <g transform=\"translate(20.878125 181.512866)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"56.50625\" xlink:href=\"#mc7955e441f\" y=\"152.765831\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.550 -->\r\n      <g transform=\"translate(20.878125 156.56505)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"56.50625\" xlink:href=\"#mc7955e441f\" y=\"127.818015\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.555 -->\r\n      <g transform=\"translate(20.878125 131.617233)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"56.50625\" xlink:href=\"#mc7955e441f\" y=\"102.870198\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 0.560 -->\r\n      <g transform=\"translate(20.878125 106.669417)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-54\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"56.50625\" xlink:href=\"#mc7955e441f\" y=\"77.922382\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 0.565 -->\r\n      <g transform=\"translate(20.878125 81.721601)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-54\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"56.50625\" xlink:href=\"#mc7955e441f\" y=\"52.974566\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 0.570 -->\r\n      <g transform=\"translate(20.878125 56.773784)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"56.50625\" xlink:href=\"#mc7955e441f\" y=\"28.026749\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_16\">\r\n      <!-- 0.575 -->\r\n      <g transform=\"translate(20.878125 31.825968)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_17\">\r\n     <!-- Loss -->\r\n     <g transform=\"translate(14.798438 126.887188)rotate(-90)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 9.8125 72.90625 \r\nL 19.671875 72.90625 \r\nL 19.671875 8.296875 \r\nL 55.171875 8.296875 \r\nL 55.171875 0 \r\nL 9.8125 0 \r\nz\r\n\" id=\"DejaVuSans-76\"/>\r\n       <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-76\"/>\r\n      <use x=\"53.962891\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"115.144531\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"167.244141\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_16\">\r\n    <path clip-path=\"url(#pd63c8e83b4)\" d=\"M 71.724432 17.083636 \r\nL 72.74237 90.723431 \r\nL 73.760309 101.53426 \r\nL 75.796186 113.27655 \r\nL 76.814125 121.217161 \r\nL 77.832063 123.591314 \r\nL 78.850002 127.40251 \r\nL 79.86794 128.736651 \r\nL 80.885879 129.506623 \r\nL 81.903818 136.720385 \r\nL 82.921756 137.569465 \r\nL 83.939695 137.947165 \r\nL 84.957633 140.167562 \r\nL 85.975572 143.249827 \r\nL 86.993511 142.057843 \r\nL 88.011449 146.621166 \r\nL 89.029388 146.006438 \r\nL 90.047326 148.905802 \r\nL 91.065265 148.342227 \r\nL 92.083203 150.68545 \r\nL 93.101142 152.267625 \r\nL 94.119081 154.581703 \r\nL 95.137019 155.869747 \r\nL 96.154958 154.424972 \r\nL 97.172896 158.431561 \r\nL 98.190835 159.714252 \r\nL 99.208774 158.501153 \r\nL 100.226712 159.037367 \r\nL 101.244651 159.097442 \r\nL 102.262589 162.898823 \r\nL 103.280528 162.079186 \r\nL 104.298466 163.356524 \r\nL 105.316405 165.862723 \r\nL 106.334344 164.266869 \r\nL 107.352282 167.747057 \r\nL 108.370221 165.637888 \r\nL 109.388159 166.364439 \r\nL 110.406098 168.167879 \r\nL 112.441975 168.743351 \r\nL 113.459914 170.607758 \r\nL 114.477852 172.177739 \r\nL 115.495791 172.138779 \r\nL 116.513729 170.271992 \r\nL 117.531668 174.64141 \r\nL 118.549607 172.496553 \r\nL 120.585484 175.697184 \r\nL 122.621361 175.990124 \r\nL 123.6393 174.618213 \r\nL 124.657238 178.345244 \r\nL 125.675177 177.013779 \r\nL 126.693115 179.971731 \r\nL 127.711054 176.485892 \r\nL 128.728992 178.436546 \r\nL 129.746931 179.886674 \r\nL 130.76487 179.888756 \r\nL 131.782808 181.324014 \r\nL 132.800747 181.990787 \r\nL 133.818685 179.093505 \r\nL 134.836624 181.061706 \r\nL 135.854563 181.898593 \r\nL 136.872501 181.964913 \r\nL 137.89044 181.075386 \r\nL 138.908378 183.782927 \r\nL 139.926317 182.550496 \r\nL 140.944255 181.558366 \r\nL 141.962194 183.795715 \r\nL 143.998071 186.257304 \r\nL 145.01601 185.240787 \r\nL 146.033948 185.409116 \r\nL 147.051887 184.392896 \r\nL 148.069826 184.630222 \r\nL 149.087764 185.668152 \r\nL 150.105703 186.397677 \r\nL 151.123641 185.391867 \r\nL 152.14158 187.75234 \r\nL 153.159518 186.476786 \r\nL 154.177457 186.635896 \r\nL 155.195396 186.568088 \r\nL 156.213334 185.905776 \r\nL 157.231273 188.036358 \r\nL 158.249211 186.27842 \r\nL 159.26715 188.980904 \r\nL 160.285089 190.02389 \r\nL 161.303027 186.621026 \r\nL 162.320966 188.615398 \r\nL 163.338904 188.153534 \r\nL 164.356843 188.781645 \r\nL 165.374781 189.163805 \r\nL 166.39272 187.265494 \r\nL 167.410659 191.338997 \r\nL 168.428597 192.598491 \r\nL 169.446536 190.11311 \r\nL 170.464474 193.683113 \r\nL 171.482413 190.685905 \r\nL 172.500352 194.101854 \r\nL 173.51829 192.529494 \r\nL 174.536229 193.984678 \r\nL 175.554167 190.844419 \r\nL 176.572106 194.103341 \r\nL 177.590044 193.134111 \r\nL 178.607983 195.578451 \r\nL 179.625922 193.095151 \r\nL 180.64386 192.268971 \r\nL 181.661799 193.176937 \r\nL 182.679737 196.654151 \r\nL 183.697676 195.000303 \r\nL 184.715615 195.091605 \r\nL 185.733553 194.450408 \r\nL 186.751492 195.187963 \r\nL 187.76943 192.35492 \r\nL 188.787369 195.40804 \r\nL 189.805307 196.556008 \r\nL 190.823246 194.377545 \r\nL 191.841185 196.49861 \r\nL 192.859123 195.757189 \r\nL 193.877062 196.707386 \r\nL 194.895 194.523271 \r\nL 195.912939 195.344991 \r\nL 196.930878 195.249525 \r\nL 197.948816 197.413713 \r\nL 198.966755 197.126126 \r\nL 199.984693 197.267987 \r\nL 201.002632 196.344556 \r\nL 202.02057 197.182038 \r\nL 203.038509 196.892666 \r\nL 204.056448 196.907239 \r\nL 205.074386 197.313489 \r\nL 206.092325 198.990832 \r\nL 207.110263 197.045531 \r\nL 208.128202 197.338768 \r\nL 209.146141 198.327032 \r\nL 210.164079 198.079892 \r\nL 211.182018 198.884957 \r\nL 212.199956 198.156026 \r\nL 213.217895 200.254786 \r\nL 214.235833 198.02636 \r\nL 215.253772 198.904288 \r\nL 216.271711 200.82996 \r\nL 217.289649 197.445535 \r\nL 218.307588 198.081379 \r\nL 219.325526 198.40168 \r\nL 221.361404 201.70194 \r\nL 222.379342 201.447068 \r\nL 223.397281 201.856589 \r\nL 224.415219 199.683776 \r\nL 225.433158 201.224909 \r\nL 226.451096 199.492845 \r\nL 227.469035 198.733282 \r\nL 228.486974 202.645892 \r\nL 229.504912 199.979096 \r\nL 230.522851 199.170462 \r\nL 231.540789 202.026405 \r\nL 232.558728 201.050632 \r\nL 233.576667 202.355925 \r\nL 235.612544 202.224772 \r\nL 236.630482 202.909389 \r\nL 237.648421 200.895091 \r\nL 238.666359 203.876835 \r\nL 239.684298 203.711777 \r\nL 240.702237 202.848719 \r\nL 241.720175 202.455852 \r\nL 242.738114 201.643352 \r\nL 243.756052 197.507395 \r\nL 244.773991 204.070443 \r\nL 245.79193 203.034297 \r\nL 246.809868 202.647379 \r\nL 247.827807 204.454091 \r\nL 248.845745 202.468046 \r\nL 249.863684 204.980491 \r\nL 250.881622 203.743897 \r\nL 251.899561 204.885322 \r\nL 252.9175 201.982092 \r\nL 253.935438 204.102265 \r\nL 254.953377 205.885482 \r\nL 255.971315 203.942263 \r\nL 256.989254 206.362811 \r\nL 258.007193 206.798504 \r\nL 259.025131 203.983602 \r\nL 260.04307 204.235203 \r\nL 261.061008 202.176593 \r\nL 262.078947 207.038804 \r\nL 263.096885 188.248702 \r\nL 264.114824 199.073212 \r\nL 265.132763 205.367409 \r\nL 266.150701 205.26659 \r\nL 267.16864 206.308387 \r\nL 268.186578 204.220631 \r\nL 269.204517 204.505244 \r\nL 270.222456 206.873151 \r\nL 271.240394 204.607847 \r\nL 273.276271 201.851831 \r\nL 274.29421 201.910121 \r\nL 275.312148 205.743622 \r\nL 276.330087 199.490465 \r\nL 277.348026 208.125508 \r\nL 278.365964 207.696953 \r\nL 279.383903 204.377064 \r\nL 280.401841 205.593434 \r\nL 281.41978 205.70496 \r\nL 282.437719 204.769633 \r\nL 283.455657 207.3368 \r\nL 284.473596 207.311521 \r\nL 285.491534 206.831218 \r\nL 286.509473 207.052782 \r\nL 287.527411 204.910899 \r\nL 288.54535 207.979186 \r\nL 290.581227 208.192423 \r\nL 291.599166 207.106314 \r\nL 292.617104 207.308249 \r\nL 293.635043 207.010551 \r\nL 294.652982 205.427782 \r\nL 295.67092 205.596408 \r\nL 296.688859 207.671079 \r\nL 297.706797 205.252018 \r\nL 298.724736 207.318064 \r\nL 299.742674 207.443269 \r\nL 300.760613 207.392116 \r\nL 301.778552 208.613543 \r\nL 302.79649 207.632119 \r\nL 303.814429 207.340963 \r\nL 304.832367 210.289696 \r\nL 305.850306 204.732458 \r\nL 306.868245 205.133652 \r\nL 307.886183 206.979621 \r\nL 308.904122 210.791412 \r\nL 309.92206 209.764188 \r\nL 310.939999 211.423389 \r\nL 311.957937 209.059347 \r\nL 312.975876 208.906186 \r\nL 313.993815 211.129557 \r\nL 315.011753 202.356818 \r\nL 316.029692 206.336342 \r\nL 317.04763 209.505152 \r\nL 318.065569 209.721362 \r\nL 319.083508 210.224565 \r\nL 320.101446 209.288346 \r\nL 321.119385 211.132531 \r\nL 322.137323 210.896989 \r\nL 323.155262 209.556007 \r\nL 324.1732 204.134979 \r\nL 325.191139 196.355263 \r\nL 326.209078 211.619079 \r\nL 327.227016 209.462326 \r\nL 328.244955 209.994376 \r\nL 329.262893 203.854827 \r\nL 331.298771 213.374341 \r\nL 332.316709 209.559873 \r\nL 333.334648 212.697158 \r\nL 334.352586 209.409686 \r\nL 335.370525 210.829479 \r\nL 336.388463 209.809988 \r\nL 337.406402 212.656117 \r\nL 338.424341 211.201528 \r\nL 339.442279 211.914696 \r\nL 341.478156 201.823875 \r\nL 342.496095 213.36869 \r\nL 343.514034 210.732526 \r\nL 344.531972 207.473604 \r\nL 345.549911 206.1695 \r\nL 346.567849 212.221019 \r\nL 347.585788 211.343983 \r\nL 348.603726 211.368667 \r\nL 349.621665 213.64557 \r\nL 350.639604 209.334741 \r\nL 351.657542 211.288964 \r\nL 352.675481 213.856725 \r\nL 353.693419 209.578907 \r\nL 354.711358 212.109196 \r\nL 355.729297 212.316782 \r\nL 356.747235 209.746047 \r\nL 357.765174 211.479895 \r\nL 358.783112 211.065318 \r\nL 360.818989 210.868736 \r\nL 361.836928 212.8182 \r\nL 362.854867 205.529493 \r\nL 363.872805 214.756364 \r\nL 364.890744 207.502155 \r\nL 365.908682 213.520067 \r\nL 366.926621 211.531643 \r\nL 367.94456 212.57909 \r\nL 368.962498 210.927026 \r\nL 369.980437 214.231153 \r\nL 370.998375 213.879625 \r\nL 372.016314 213.979849 \r\nL 373.034252 213.129282 \r\nL 374.052191 207.826917 \r\nL 375.07013 210.568063 \r\nL 376.088068 210.863085 \r\nL 376.088068 210.863085 \r\n\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 56.50625 224.64 \r\nL 56.50625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 391.30625 224.64 \r\nL 391.30625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 56.50625 224.64 \r\nL 391.30625 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 56.50625 7.2 \r\nL 391.30625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 306.65 132.098125 \r\nL 384.30625 132.098125 \r\nQ 386.30625 132.098125 386.30625 130.098125 \r\nL 386.30625 101.741875 \r\nQ 386.30625 99.741875 384.30625 99.741875 \r\nL 306.65 99.741875 \r\nQ 304.65 99.741875 304.65 101.741875 \r\nL 304.65 130.098125 \r\nQ 304.65 132.098125 306.65 132.098125 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_17\">\r\n     <path d=\"M 308.65 107.840313 \r\nL 328.65 107.840313 \r\n\" style=\"fill:none;stroke:#ff0000;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_18\"/>\r\n    <g id=\"text_18\">\r\n     <!-- Loss -->\r\n     <g transform=\"translate(336.65 111.340313)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-76\"/>\r\n      <use x=\"53.962891\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"115.144531\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"167.244141\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_19\">\r\n     <path d=\"M 308.65 122.518438 \r\nL 328.65 122.518438 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_20\"/>\r\n    <g id=\"text_19\">\r\n     <!-- Accuracy -->\r\n     <g transform=\"translate(336.65 126.018438)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 34.1875 63.1875 \r\nL 20.796875 26.90625 \r\nL 47.609375 26.90625 \r\nz\r\nM 28.609375 72.90625 \r\nL 39.796875 72.90625 \r\nL 67.578125 0 \r\nL 57.328125 0 \r\nL 50.6875 18.703125 \r\nL 17.828125 18.703125 \r\nL 11.1875 0 \r\nL 0.78125 0 \r\nz\r\n\" id=\"DejaVuSans-65\"/>\r\n       <path d=\"M 8.5 21.578125 \r\nL 8.5 54.6875 \r\nL 17.484375 54.6875 \r\nL 17.484375 21.921875 \r\nQ 17.484375 14.15625 20.5 10.265625 \r\nQ 23.53125 6.390625 29.59375 6.390625 \r\nQ 36.859375 6.390625 41.078125 11.03125 \r\nQ 45.3125 15.671875 45.3125 23.6875 \r\nL 45.3125 54.6875 \r\nL 54.296875 54.6875 \r\nL 54.296875 0 \r\nL 45.3125 0 \r\nL 45.3125 8.40625 \r\nQ 42.046875 3.421875 37.71875 1 \r\nQ 33.40625 -1.421875 27.6875 -1.421875 \r\nQ 18.265625 -1.421875 13.375 4.4375 \r\nQ 8.5 10.296875 8.5 21.578125 \r\nz\r\nM 31.109375 56 \r\nz\r\n\" id=\"DejaVuSans-117\"/>\r\n       <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n       <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n       <path d=\"M 32.171875 -5.078125 \r\nQ 28.375 -14.84375 24.75 -17.8125 \r\nQ 21.140625 -20.796875 15.09375 -20.796875 \r\nL 7.90625 -20.796875 \r\nL 7.90625 -13.28125 \r\nL 13.1875 -13.28125 \r\nQ 16.890625 -13.28125 18.9375 -11.515625 \r\nQ 21 -9.765625 23.484375 -3.21875 \r\nL 25.09375 0.875 \r\nL 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 11.921875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nz\r\n\" id=\"DejaVuSans-121\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-65\"/>\r\n      <use x=\"66.658203\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"121.638672\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"176.619141\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"239.998047\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"281.111328\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"342.390625\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"397.371094\" xlink:href=\"#DejaVuSans-121\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_2\">\r\n   <g id=\"matplotlib.axis_3\">\r\n    <g id=\"ytick_9\">\r\n     <g id=\"line2d_21\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 3.5 0 \r\n\" id=\"m2d6c5049e1\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"391.30625\" xlink:href=\"#m2d6c5049e1\" y=\"182.077374\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_20\">\r\n      <!-- 0.720 -->\r\n      <g transform=\"translate(398.30625 185.876593)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_10\">\r\n     <g id=\"line2d_22\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"391.30625\" xlink:href=\"#m2d6c5049e1\" y=\"134.465738\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_21\">\r\n      <!-- 0.725 -->\r\n      <g transform=\"translate(398.30625 138.264957)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_11\">\r\n     <g id=\"line2d_23\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"391.30625\" xlink:href=\"#m2d6c5049e1\" y=\"86.854102\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_22\">\r\n      <!-- 0.730 -->\r\n      <g transform=\"translate(398.30625 90.65332)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_12\">\r\n     <g id=\"line2d_24\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"391.30625\" xlink:href=\"#m2d6c5049e1\" y=\"39.242466\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_23\">\r\n      <!-- 0.735 -->\r\n      <g transform=\"translate(398.30625 43.041684)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_24\">\r\n     <!-- Accuracy -->\r\n     <g transform=\"translate(438.532813 138.748125)rotate(-90)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-65\"/>\r\n      <use x=\"66.658203\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"121.638672\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"176.619141\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"239.998047\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"281.111328\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"342.390625\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"397.371094\" xlink:href=\"#DejaVuSans-121\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_25\">\r\n    <path clip-path=\"url(#pd63c8e83b4)\" d=\"M 71.724432 214.756364 \r\nL 72.74237 156.638961 \r\nL 73.760309 138.871028 \r\nL 74.778248 132.577757 \r\nL 75.796186 133.688501 \r\nL 76.814125 117.770862 \r\nL 77.832063 132.207698 \r\nL 78.850002 113.32902 \r\nL 79.86794 132.947816 \r\nL 80.885879 101.113105 \r\nL 81.903818 98.892184 \r\nL 82.921756 97.78144 \r\nL 83.939695 105.184888 \r\nL 84.957633 104.074711 \r\nL 85.975572 90.377993 \r\nL 86.993511 93.339599 \r\nL 88.011449 90.748052 \r\nL 89.029388 99.632302 \r\nL 90.047326 85.936151 \r\nL 91.065265 85.195466 \r\nL 92.083203 80.383566 \r\nL 93.101142 74.090295 \r\nL 94.119081 79.272822 \r\nL 95.137019 67.057474 \r\nL 96.154958 82.974545 \r\nL 97.172896 81.123684 \r\nL 98.190835 75.571098 \r\nL 99.208774 71.869374 \r\nL 100.226712 64.835986 \r\nL 101.244651 73.350177 \r\nL 102.262589 67.427533 \r\nL 103.280528 64.835986 \r\nL 104.298466 64.095868 \r\nL 105.316405 64.095868 \r\nL 106.334344 62.985124 \r\nL 107.352282 64.095868 \r\nL 108.370221 70.018512 \r\nL 109.388159 61.874947 \r\nL 110.406098 62.245006 \r\nL 111.424037 65.94673 \r\nL 113.459914 56.692421 \r\nL 114.477852 57.432538 \r\nL 115.495791 65.576671 \r\nL 117.531668 51.139835 \r\nL 118.549607 58.913341 \r\nL 119.567545 57.803165 \r\nL 120.585484 49.659032 \r\nL 121.603422 59.654027 \r\nL 122.621361 47.80817 \r\nL 123.6393 58.543282 \r\nL 124.657238 50.399717 \r\nL 125.675177 60.024085 \r\nL 126.693115 47.068052 \r\nL 127.711054 55.952303 \r\nL 128.728992 57.062479 \r\nL 129.746931 51.139835 \r\nL 130.76487 43.736388 \r\nL 131.782808 41.885526 \r\nL 132.800747 50.399717 \r\nL 133.818685 54.841559 \r\nL 134.836624 52.990697 \r\nL 135.854563 49.288973 \r\nL 136.872501 47.068052 \r\nL 137.89044 51.509894 \r\nL 138.908378 45.217191 \r\nL 139.926317 47.068052 \r\nL 140.944255 44.847132 \r\nL 141.962194 49.288973 \r\nL 142.980133 44.847132 \r\nL 143.998071 44.476505 \r\nL 145.01601 42.255585 \r\nL 146.033948 48.918914 \r\nL 148.069826 41.515467 \r\nL 149.087764 44.476505 \r\nL 150.105703 56.322362 \r\nL 151.123641 42.255585 \r\nL 152.14158 40.404723 \r\nL 154.177457 53.730815 \r\nL 155.195396 41.885526 \r\nL 156.213334 47.80817 \r\nL 157.231273 52.250579 \r\nL 158.249211 42.99627 \r\nL 159.26715 45.957308 \r\nL 160.285089 47.068052 \r\nL 161.303027 38.92392 \r\nL 162.320966 41.145408 \r\nL 163.338904 38.553861 \r\nL 164.356843 42.99627 \r\nL 165.374781 43.736388 \r\nL 166.39272 45.217191 \r\nL 167.410659 40.774782 \r\nL 168.428597 45.587249 \r\nL 169.446536 37.813743 \r\nL 170.464474 40.404723 \r\nL 171.482413 41.515467 \r\nL 172.500352 37.443684 \r\nL 173.51829 35.222196 \r\nL 174.536229 41.885526 \r\nL 175.554167 42.255585 \r\nL 176.572106 36.702999 \r\nL 177.590044 34.112019 \r\nL 178.607983 36.33294 \r\nL 179.625922 40.034664 \r\nL 180.64386 44.476505 \r\nL 181.661799 33.371334 \r\nL 182.679737 37.813743 \r\nL 183.697676 33.741961 \r\nL 184.715615 31.891099 \r\nL 185.733553 40.034664 \r\nL 186.751492 34.112019 \r\nL 187.76943 32.261158 \r\nL 188.787369 31.520472 \r\nL 189.805307 40.034664 \r\nL 190.823246 31.520472 \r\nL 191.841185 33.371334 \r\nL 192.859123 33.741961 \r\nL 193.877062 35.962881 \r\nL 194.895 39.294546 \r\nL 195.912939 36.702999 \r\nL 196.930878 38.183802 \r\nL 197.948816 35.592822 \r\nL 198.966755 37.813743 \r\nL 199.984693 34.482078 \r\nL 201.002632 29.66961 \r\nL 202.02057 36.702999 \r\nL 203.038509 30.780355 \r\nL 204.056448 37.073058 \r\nL 205.074386 28.929493 \r\nL 206.092325 34.852137 \r\nL 207.110263 32.631216 \r\nL 208.128202 33.001275 \r\nL 209.146141 31.520472 \r\nL 210.164079 30.780355 \r\nL 211.182018 28.559434 \r\nL 212.199956 34.482078 \r\nL 213.217895 35.222196 \r\nL 214.235833 30.410296 \r\nL 215.253772 36.702999 \r\nL 216.271711 38.553861 \r\nL 217.289649 37.073058 \r\nL 219.325526 36.33294 \r\nL 220.343465 30.410296 \r\nL 221.361404 33.371334 \r\nL 222.379342 37.073058 \r\nL 223.397281 31.520472 \r\nL 224.415219 38.553861 \r\nL 226.451096 30.780355 \r\nL 227.469035 40.034664 \r\nL 228.486974 31.891099 \r\nL 229.504912 35.222196 \r\nL 230.522851 27.44869 \r\nL 231.540789 37.813743 \r\nL 232.558728 30.410296 \r\nL 233.576667 28.929493 \r\nL 234.594605 33.001275 \r\nL 235.612544 31.891099 \r\nL 236.630482 29.66961 \r\nL 237.648421 30.780355 \r\nL 238.666359 28.929493 \r\nL 239.684298 28.189375 \r\nL 241.720175 35.592822 \r\nL 242.738114 35.222196 \r\nL 243.756052 31.891099 \r\nL 244.773991 32.261158 \r\nL 245.79193 31.150413 \r\nL 246.809868 33.001275 \r\nL 247.827807 33.001275 \r\nL 248.845745 31.520472 \r\nL 249.863684 31.891099 \r\nL 250.881622 30.040237 \r\nL 251.899561 29.66961 \r\nL 252.9175 27.44869 \r\nL 253.935438 30.780355 \r\nL 254.953377 32.631216 \r\nL 255.971315 29.66961 \r\nL 256.989254 31.520472 \r\nL 258.007193 28.189375 \r\nL 259.025131 35.222196 \r\nL 260.04307 34.112019 \r\nL 261.061008 30.410296 \r\nL 262.078947 30.410296 \r\nL 263.096885 29.66961 \r\nL 264.114824 31.520472 \r\nL 265.132763 30.780355 \r\nL 266.150701 30.780355 \r\nL 267.16864 26.338513 \r\nL 268.186578 33.371334 \r\nL 269.204517 30.410296 \r\nL 270.222456 33.741961 \r\nL 271.240394 29.299552 \r\nL 272.258333 29.66961 \r\nL 273.276271 29.299552 \r\nL 274.29421 30.410296 \r\nL 275.312148 26.338513 \r\nL 276.330087 32.631216 \r\nL 277.348026 26.708572 \r\nL 278.365964 31.150413 \r\nL 279.383903 29.66961 \r\nL 280.401841 28.559434 \r\nL 281.41978 32.631216 \r\nL 282.437719 27.078631 \r\nL 283.455657 27.818749 \r\nL 284.473596 34.482078 \r\nL 285.491534 31.150413 \r\nL 287.527411 31.891099 \r\nL 288.54535 26.708572 \r\nL 289.563289 30.040237 \r\nL 290.581227 30.410296 \r\nL 291.599166 26.338513 \r\nL 292.617104 28.189375 \r\nL 293.635043 37.073058 \r\nL 294.652982 33.001275 \r\nL 295.67092 27.818749 \r\nL 296.688859 31.520472 \r\nL 297.706797 24.85771 \r\nL 298.724736 27.078631 \r\nL 299.742674 33.371334 \r\nL 300.760613 24.117025 \r\nL 301.778552 25.227769 \r\nL 302.79649 30.410296 \r\nL 303.814429 27.818749 \r\nL 304.832367 33.001275 \r\nL 305.850306 26.708572 \r\nL 306.868245 25.967887 \r\nL 307.886183 26.708572 \r\nL 308.904122 25.227769 \r\nL 309.92206 30.040237 \r\nL 310.939999 23.746966 \r\nL 311.957937 27.078631 \r\nL 312.975876 23.746966 \r\nL 313.993815 23.006848 \r\nL 315.011753 30.780355 \r\nL 316.029692 26.708572 \r\nL 317.04763 21.896104 \r\nL 318.065569 25.597828 \r\nL 319.083508 26.338513 \r\nL 320.101446 26.708572 \r\nL 321.119385 27.44869 \r\nL 322.137323 23.006848 \r\nL 323.155262 24.117025 \r\nL 324.1732 26.708572 \r\nL 325.191139 23.376907 \r\nL 326.209078 24.117025 \r\nL 327.227016 25.967887 \r\nL 328.244955 26.708572 \r\nL 329.262893 26.338513 \r\nL 330.280832 27.818749 \r\nL 331.298771 23.746966 \r\nL 332.316709 21.896104 \r\nL 333.334648 27.818749 \r\nL 334.352586 24.117025 \r\nL 335.370525 25.967887 \r\nL 336.388463 21.896104 \r\nL 337.406402 21.896104 \r\nL 338.424341 23.006848 \r\nL 339.442279 24.85771 \r\nL 340.460218 29.66961 \r\nL 341.478156 23.376907 \r\nL 342.496095 25.967887 \r\nL 343.514034 19.675184 \r\nL 344.531972 28.189375 \r\nL 345.549911 21.896104 \r\nL 346.567849 25.597828 \r\nL 347.585788 30.040237 \r\nL 348.603726 18.934498 \r\nL 349.621665 24.117025 \r\nL 350.639604 23.746966 \r\nL 351.657542 25.967887 \r\nL 352.675481 17.083636 \r\nL 353.693419 29.66961 \r\nL 354.711358 26.708572 \r\nL 355.729297 26.708572 \r\nL 356.747235 25.597828 \r\nL 357.765174 23.746966 \r\nL 358.783112 18.564439 \r\nL 359.801051 23.746966 \r\nL 360.818989 25.227769 \r\nL 362.854867 25.967887 \r\nL 363.872805 22.63679 \r\nL 364.890744 27.818749 \r\nL 365.908682 21.896104 \r\nL 366.926621 22.63679 \r\nL 367.94456 19.675184 \r\nL 368.962498 25.597828 \r\nL 369.980437 22.63679 \r\nL 370.998375 18.564439 \r\nL 373.034252 22.266163 \r\nL 374.052191 28.189375 \r\nL 375.07013 25.597828 \r\nL 376.088068 25.227769 \r\nL 376.088068 25.227769 \r\n\" style=\"fill:none;stroke:#0000ff;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_8\">\r\n    <path d=\"M 56.50625 224.64 \r\nL 56.50625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_9\">\r\n    <path d=\"M 391.30625 224.64 \r\nL 391.30625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_10\">\r\n    <path d=\"M 56.50625 224.64 \r\nL 391.30625 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_11\">\r\n    <path d=\"M 56.50625 7.2 \r\nL 391.30625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pd63c8e83b4\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"56.50625\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# Visualize Loss/Accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "history_df = pd.DataFrame(fit_model.history,\n",
    "                          index=range(1, len(fit_model.history[\"loss\"]) + 1))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "loss = ax.plot(history_df[\"loss\"], color=\"red\", label=\"Loss\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "acc = ax2.plot(history_df[\"accuracy\"], color=\"blue\", label=\"Accuracy\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "\n",
    "curves = loss + acc\n",
    "labs = [l.get_label() for l in curves]\n",
    "ax.legend(curves, labs, loc=\"center right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.save(\"AlphabetSoupCharityOptimization.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}